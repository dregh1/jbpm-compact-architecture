package mg.orange.workflow.repository;

import io.quarkus.scheduler.Scheduled;
import mg.orange.workflow.model.stats.ProcessStatsDTO;
import mg.orange.workflow.service.AlertService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import jakarta.persistence.EntityManager;
import jakarta.persistence.Query;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.util.*;
import java.util.stream.Collectors;

@ApplicationScoped
public class ProcessStatsRepository {

    private static final Logger logger = LoggerFactory.getLogger(ProcessStatsRepository.class);

    private final EntityManager entityManager;
    private final AlertService alertService;

    @Inject
    public ProcessStatsRepository(EntityManager entityManager, AlertService alertService) {
        this.entityManager = entityManager;
        this.alertService = alertService;
    }

    /**
     * R√©cup√®re toutes les statistiques avanc√©es pour le dashboard
     */
    public ProcessStatsDTO getAdvancedDashboardStats() {
        logger.info("D√©but de la r√©cup√©ration des statistiques avanc√©es du dashboard");

        try {
            ProcessStatsDTO stats = new ProcessStatsDTO();

            // Stats de base
            logger.debug("R√©cup√©ration des statistiques de base");
            ProcessStatsDTO basicStats = getBasicStats();
            stats.setTotalInstances(basicStats.getTotalInstances());
            stats.setActiveInstances(basicStats.getActiveInstances());
            stats.setCompletedInstances(basicStats.getCompletedInstances());
            stats.setAbortedInstances(basicStats.getAbortedInstances());
            stats.setSuspendedInstances(basicStats.getSuspendedInstances());
            stats.setErrorInstances(basicStats.getErrorInstances());
            stats.setInstancesByProcess(basicStats.getInstancesByProcess());
            stats.setAverageDurationMs(basicStats.getAverageDurationMs());
            stats.setInstancesLast24Hours(basicStats.getInstancesLast24Hours());
            stats.setInstancesLast7Days(basicStats.getInstancesLast7Days());

            // Nouvelles m√©triques
            logger.debug("Calcul du taux de compl√©tion global");
            stats.setOverallCompletionRate(calculateOverallCompletionRate());

            logger.debug("R√©cup√©ration du top 5 des processus les plus utilis√©s");
            stats.setTopProcesses(getTopProcesses());

            logger.debug("D√©tection des t√¢ches probl√©matiques (Probl√®mes Critiques)");
            stats.setBottleneckTasks(detectBottleneckTasks());

            logger.debug("G√©n√©ration des alertes de processus");
            stats.setActiveAlerts(generateProcessAlerts());

            logger.debug("R√©cup√©ration des statistiques temporelles");
            stats.setTimelineStats(getTimelineStats("daily"));

            logger.info("Statistiques avanc√©es r√©cup√©r√©es avec succ√®s");
            return stats;
        } catch (Exception e) {
            logger.error("Erreur lors de la r√©cup√©ration des statistiques avanc√©es: {}", e.getMessage(), e);
            throw e;
        }
    }

    /**
     * Taux de compl√©tion global des processus
     */
    private Double calculateOverallCompletionRate() {
        try {
            String sql = "SELECT " +
                "ROUND(COUNT(CASE WHEN state = 2 THEN 1 END) * 100.0 / NULLIF(COUNT(*), 0), 2) " +
                "FROM processes";

            Query query = entityManager.createNativeQuery(sql);
            Object result = query.getSingleResult();

            if (result == null) return 0.0;

            // Gestion plus robuste du type de retour
            return Double.parseDouble(result.toString());

        } catch (Exception e) {
            logger.error("Error calculating completion rate", e);
            return 0.0;
        }
    }

    /**
     * Top 5 des processus les plus utilis√©s
     */
    @SuppressWarnings("unchecked")
    public Map<String, Long> getTopProcesses() {
        logger.info("üîç R√©cup√©ration du top 5 des processus les plus utilis√©s");

        String sql = "SELECT process_id, COUNT(*) as cnt FROM process_instances GROUP BY process_id ORDER BY cnt DESC LIMIT 5";

        Map<String, Long> topProcesses = new LinkedHashMap<>();
        
        try {
            logger.info("üîÑ Ex√©cution SQL: {}", sql);
            Query query = entityManager.createNativeQuery(sql);
            List<Object[]> results = (List<Object[]>) query.getResultList();
            logger.info("  ‚úÖ R√©sultats: {} lignes", results.size());

            if (!results.isEmpty()) {
                for (Object[] row : results) {
                    String processId = row[0] != null ? row[0].toString() : "unknown";
                    Long count = extractLong(row[1]);
                    logger.info("    Process: {} = {} instances", processId, count);
                    topProcesses.put(processId, count);
                }
                logger.info("üìä Succ√®s! topProcesses size: {}", topProcesses.size());
                return topProcesses;
            } else {
                logger.warn("‚ö†Ô∏è Aucun r√©sultat retourn√©!");
            }
        } catch (Exception e) {
            logger.error("‚ùå ERREUR: {}", e.getMessage(), e);
        }

        logger.error("‚ùå Retour d'une map vide");
        return topProcesses;
    }

    /**
     * D√©tection des t√¢ches probl√©matiques - Premi√®re t√¢che non-compl√©t√©e apr√®s la derni√®re t√¢che compl√©t√©e
     * Identifie pr√©cis√©ment la t√¢che qui cause l'√©chec dans les processus en erreur
     * S√©v√©rit√© bas√©e sur le ratio : moiti√© (MEDIUM), plus de moiti√© (HIGH), tous (CRITICAL)
     */
    @SuppressWarnings("unchecked")
    public List<ProcessStatsDTO.BottleneckTask> detectBottleneckTasks() {
        logger.debug("D√©tection des t√¢ches qui causent des √©checs de processus (premi√®re apr√®s derni√®re completed)");

        // CTE pour identifier la premi√®re t√¢che probl√©matique apr√®s la derni√®re t√¢che compl√©t√©e
        String sql = "WITH last_completed_tasks AS ( " +
            "    SELECT " +
            "        t.process_instance_id, " +
            "        MAX(t.started) as last_completed_time " +
            "    FROM tasks t " +
            "    JOIN processes p ON t.process_instance_id = p.id " +
            "    WHERE p.state = 5 " +
            "      AND t.state = 'Completed' " +
            "      AND p.start_time >= NOW() - INTERVAL '30 days' " +
            "    GROUP BY t.process_instance_id " +
            "), " +
            "first_failed_tasks AS ( " +
            "    SELECT DISTINCT ON (t.process_instance_id) " +
            "        t.process_instance_id, " +
            "        t.name, " +
            "        t.process_id, " +
            "        t.started " +
            "    FROM tasks t " +
            "    JOIN processes p ON t.process_instance_id = p.id " +
            "    LEFT JOIN last_completed_tasks lct ON t.process_instance_id = lct.process_instance_id " +
            "    WHERE p.state = 5 " +
            "      AND t.state != 'Completed' " +
            "      AND p.start_time >= NOW() - INTERVAL '30 days' " +
            "      AND (lct.last_completed_time IS NULL OR t.started > lct.last_completed_time) " +
            "    ORDER BY t.process_instance_id, t.started ASC " +
            "), " +
            "all_task_instances AS ( " +
            "    SELECT " +
            "        t.name, " +
            "        t.process_id, " +
            "        COUNT(DISTINCT t.process_instance_id) as total_instances " +
            "    FROM tasks t " +
            "    JOIN processes p ON t.process_instance_id = p.id " +
            "    WHERE p.start_time >= NOW() - INTERVAL '30 days' " +
            "    GROUP BY t.name, t.process_id " +
            ") " +
            "SELECT " +
            "    fft.name as task_name, " +
            "    fft.process_id, " +
            "    COUNT(DISTINCT fft.process_instance_id) as failed_instances, " +
            "    COALESCE(ati.total_instances, 0) as total_instances, " +
            "    ROUND(COUNT(DISTINCT fft.process_instance_id) * 100.0 / " +
            "          NULLIF(COALESCE(ati.total_instances, 0), 0), 2) as failure_rate " +
            "FROM first_failed_tasks fft " +
            "LEFT JOIN all_task_instances ati ON fft.name = ati.name AND fft.process_id = ati.process_id " +
            "GROUP BY fft.name, fft.process_id, ati.total_instances " +
            "HAVING COUNT(DISTINCT fft.process_instance_id) >= 2 " +
            "  AND COUNT(DISTINCT fft.process_instance_id) >= COALESCE(ati.total_instances, 0) * 0.5 " +
            "ORDER BY failure_rate DESC, failed_instances DESC " +
            "LIMIT 10";

        Map<String, Long> topProcesses = new LinkedHashMap<>();
        
        try {
            logger.debug("V√©rification de l'existence de la table tasks");
            // V√©rifier si la table existe
            try {
                Query checkQuery = entityManager.createNativeQuery("SELECT COUNT(*) FROM tasks");
                Object checkResult = checkQuery.getSingleResult();
                logger.debug("Table tasks accessible: {} enregistrements", checkResult);
            } catch (Exception tableCheckError) {
                logger.warn("Table tasks inaccessible: {}", tableCheckError.getMessage());
                return new ArrayList<>();
            }

            Query query = entityManager.createNativeQuery(sql);
            List<Object[]> results = query.getResultList();
            logger.debug("T√¢ches probl√©matiques d√©tect√©es: {} r√©sultats", results.size());

            return results.stream()
                .map(row -> {
                    ProcessStatsDTO.BottleneckTask bottleneck = new ProcessStatsDTO.BottleneckTask();
                    bottleneck.setTaskName((String) row[0]);
                    bottleneck.setProcessId((String) row[1]);
                    
                    long failedInstances = extractLong(row[2]);
                    long totalInstances = extractLong(row[3]);
                    double failureRate = extractDouble(row[4]);
                    
                    bottleneck.setStuckCount(failedInstances);  // Nombre de processus en √©chec
                    bottleneck.setAverageWaitingTimeMs(0L);     // Non utilis√©
                    
                    // D√©terminer la s√©v√©rit√© bas√©e sur le ratio d'√©chec
                    if (failureRate >= 95.0) {  // ‚â•95% = tous/presque tous √©chouent
                        bottleneck.setSeverity("CRITICAL");
                    } else if (failureRate >= 75.0) {  // 75-95% = plus que la moiti√©
                        bottleneck.setSeverity("HIGH");
                    } else {  // 50-75% = la moiti√©
                        bottleneck.setSeverity("MEDIUM");
                    }

                    logger.debug("T√¢che probl√©matique: {} sur {} - {}% √©checs ({}/{} processus) - {}",
                        bottleneck.getTaskName(),
                        bottleneck.getProcessId(),
                        failureRate,
                        failedInstances,
                        totalInstances,
                        bottleneck.getSeverity());

                    return bottleneck;
                })
                .toList();
        } catch (Exception e) {
            logger.error("Erreur lors de la d√©tection des t√¢ches probl√©matiques: {}", e.getMessage(), e);
            return new ArrayList<>();
        }
    }

    /**
     * G√©n√®re la liste des alertes actives √† afficher dans le dashboard
     * Simplifi√©: uniquement les processus en erreur (state=5)
     */
    private List<ProcessStatsDTO.ProcessAlert> generateProcessAlerts() {
        logger.debug("G√©n√©ration des alertes de processus (erreurs uniquement)");
        return alertService.generateAllAlerts();
    }


    /**
     * Extrait un Long de fa√ßon s√©curis√©e depuis un Object
     */
    private long extractLong(Object obj) {
        if (obj == null) return 0L;
        if (obj instanceof Long) return (Long) obj;
        if (obj instanceof Integer) return ((Integer) obj).longValue();
        if (obj instanceof BigInteger) return ((BigInteger) obj).longValue();
        if (obj instanceof BigDecimal) return ((BigDecimal) obj).longValue();
        return Long.parseLong(obj.toString());
    }

    /**
     * Extrait un Double de fa√ßon s√©curis√©e depuis un Object
     */
    private double extractDouble(Object obj) {
        if (obj == null) return 0.0;
        if (obj instanceof Double) return (Double) obj;
        if (obj instanceof Float) return ((Float) obj).doubleValue();
        if (obj instanceof BigDecimal) return ((BigDecimal) obj).doubleValue();
        return Double.parseDouble(obj.toString());
    }

    /**
     * R√©cup√®re les statistiques temporelles (par p√©riode)
      Sauvegarde une alerte en base (d√©l√©gu√© √† AlertService)
     */
    public void saveAlertToDatabase(ProcessStatsDTO.ProcessAlert alert) {
        alertService.saveAlertToDatabase(alert);
    }

    /**
     * R√©sout une alerte (d√©l√©gu√© √† AlertService)
     */
    public void resolveAlert(String instanceId, String alertType) {
        alertService.resolveAlert(instanceId, alertType);
    }

    /**
     * R√©sout toutes les alertes d'une instance (d√©l√©gu√© √† AlertService)
     */
    public void resolveAllAlertsForInstance(String instanceId) {
        alertService.resolveAllAlertsForInstance(instanceId);
    }

    /**
     * Nettoyage des anciennes alertes (via AlertService)
     */
    @Scheduled(cron = "0 0 2 * * ?") // Tous les jours √† 2h du matin
    public void cleanupOldAlerts() {
        logger.info("üßπ Nettoyage des alertes r√©solues depuis plus de 30 jours...");
        // Nettoyage via AlertService si n√©cessaire
    }

    /**
     * Statistiques temporelles pour graphiques
     */
    @SuppressWarnings("unchecked")
    public Map<String, Long> getTimelineStats(String period) {
        logger.debug("R√©cup√©ration des statistiques temporelles pour la p√©riode: {}", period);

        String sql;

        switch (period.toUpperCase()) {
            case "HOURLY":
                sql = "SELECT " +
                    "TO_CHAR(DATE_TRUNC('hour', start_time), 'YYYY-MM-DD HH24:00') as time_period, " +
                    "COUNT(*) as count " +
                    "FROM processes " +
                    "WHERE start_time >= NOW() - INTERVAL '24 hours' " +
                    "GROUP BY DATE_TRUNC('hour', start_time) " +
                    "ORDER BY time_period";
                break;
            case "WEEKLY":
                sql = "SELECT " +
                    "TO_CHAR(DATE_TRUNC('week', start_time), 'YYYY-\"W\"IW') as time_period, " +
                    "COUNT(*) as count " +
                    "FROM processes " +
                    "WHERE start_time >= NOW() - INTERVAL '12 weeks' " +
                    "GROUP BY DATE_TRUNC('week', start_time) " +
                    "ORDER BY time_period";
                break;
            default: // DAILY
                sql = "SELECT " +
                    "TO_CHAR(DATE_TRUNC('day', start_time), 'YYYY-MM-DD') as time_period, " +
                    "COUNT(*) as count " +
                    "FROM processes " +
                    "WHERE start_time >= NOW() - INTERVAL '30 days' " +
                    "GROUP BY DATE_TRUNC('day', start_time) " +
                    "ORDER BY time_period";
        }

        try {
            logger.debug("Ex√©cution de la requ√™te temporelle: {}", sql.substring(0, Math.min(100, sql.length())));
            Query query = entityManager.createNativeQuery(sql);
            List<Object[]> results = (List<Object[]>) query.getResultList();
            logger.debug("Statistiques temporelles r√©cup√©r√©es: {} r√©sultats", results.size());

            return results.stream()
                .collect(Collectors.toMap(
                    row -> (String) row[0],
                    row -> ((BigInteger) row[1]).longValue()
                ));
        } catch (Exception e) {
            logger.error("Erreur lors de la r√©cup√©ration des statistiques temporelles: {}", e.getMessage(), e);
            // Retourner une map vide en cas d'erreur
            return new HashMap<>();
        }
    }

    private ProcessStatsDTO getBasicStats() {
        ProcessStatsDTO stats = new ProcessStatsDTO();

        try {
            logger.debug("Ex√©cution de la requ√™te SQL pour les statistiques de base");
            // V√©rifier d'abord si la table processes existe
            try {
                Query checkTableQuery = entityManager.createNativeQuery("SELECT COUNT(*) FROM processes");
                Object tableCheck = checkTableQuery.getSingleResult();
                logger.debug("Table processes existe et contient {} enregistrements", tableCheck);
            } catch (Exception tableCheckError) {
                logger.warn("La table processes pourrait ne pas exister ou √™tre vide: {}", tableCheckError.getMessage());
                // Continuer malgr√© l'erreur de v√©rification
            }

            // Requ√™te unique optimis√©e pour toutes les statistiques de base
            String sql = "SELECT " +
                "COUNT(*) as total, " +
                "COUNT(CASE WHEN state = 1 THEN 1 END) as active, " +
                "COUNT(CASE WHEN state = 2 THEN 1 END) as completed, " +
                "COUNT(CASE WHEN state = 3 THEN 1 END) as aborted, " +
                "COUNT(CASE WHEN state = 4 THEN 1 END) as suspended, " +
                "COUNT(CASE WHEN state = 5 THEN 1 END) as error, " +
                "COUNT(CASE WHEN start_time >= CURRENT_TIMESTAMP - INTERVAL '24 HOURS' THEN 1 END) as last_24h, " +
                "COUNT(CASE WHEN start_time >= CURRENT_TIMESTAMP - INTERVAL '7 DAYS' THEN 1 END) as last_7d " +
                "FROM processes";

            Query query = entityManager.createNativeQuery(sql);
            Object resultObj = query.getSingleResult();
            logger.debug("R√©sultat de la requ√™te SQL obtenu: {}", resultObj != null ? "non-null" : "null");

            // V√©rification de nullit√© et de type pour √©viter NullPointerException et ClassCastException
            if (resultObj == null || !(resultObj instanceof Object[])) {
                logger.warn("Aucun r√©sultat valide retourn√© par la requ√™te de statistiques de base, utilisation des valeurs par d√©faut");
                handleStatsError(stats, new RuntimeException("Invalid or null results returned from basic stats query"));
                return stats;
            }

            Object[] result = (Object[]) resultObj;

            // V√©rification de la longueur du tableau pour √©viter ArrayIndexOutOfBoundsException
            if (result.length < 8) {
                logger.warn("R√©sultat incomplet retourn√© par la requ√™te de statistiques de base ({} √©l√©ments au lieu de 8), utilisation des valeurs par d√©faut", result.length);
                handleStatsError(stats, new RuntimeException("Incomplete results returned from basic stats query"));
                return stats;
            }

            // Extraction des r√©sultats
            stats.setTotalInstances(extractLong(result[0]));
            stats.setActiveInstances(extractLong(result[1]));
            stats.setCompletedInstances(extractLong(result[2]));
            stats.setAbortedInstances(extractLong(result[3]));
            stats.setSuspendedInstances(extractLong(result[4]));
            stats.setErrorInstances(extractLong(result[5]));
            stats.setInstancesLast24Hours(extractLong(result[6]));
            stats.setInstancesLast7Days(extractLong(result[7]));

            // M√©triques suppl√©mentaires
            logger.debug("R√©cup√©ration des instances par processus");
            stats.setInstancesByProcess(getInstancesByProcess());
            logger.debug("Calcul de la dur√©e moyenne");
            stats.setAverageDurationMs(getAverageDuration());
            logger.debug("Statistiques de base r√©cup√©r√©es avec succ√®s: total={}", stats.getTotalInstances());

        } catch (Exception e) {
            // Fallback en cas d'erreur
            logger.error("Erreur lors de la r√©cup√©ration des statistiques de base: {}", e.getMessage(), e);
            handleStatsError(stats, e);
        }

        return stats;
    }
    /**
     * R√©cup√®re la r√©partition des instances par processus
     */
    @SuppressWarnings("unchecked")
    private Map<String, Long> getInstancesByProcess() {
        String sql = "SELECT process_id, process_name, COUNT(*) as count FROM processes GROUP BY process_id, process_name";

        try {
            Query query = entityManager.createNativeQuery(sql, Object[].class);
            List<Object[]> results = query.getResultList();

            Map<String, Long> byProcess = new HashMap<>();
            for (Object[] row : results) {
                String processId = (String) row[0];
                String processName = (String) row[1];
                String key = processName != null ? processName : processId;
                Long count = extractLong(row[2]);
                byProcess.put(key, count);
            }

            return byProcess;
        } catch (Exception e) {
            // Retourner une map vide en cas d'erreur
            return new HashMap<>();
        }
    }

    /**
     * Calcule la dur√©e moyenne d'ex√©cution
     */
    private Double getAverageDuration() {
        String sql = "SELECT AVG(EXTRACT(EPOCH FROM (end_time - start_time)) * 1000) " +
                     "FROM processes " +
                     "WHERE state = 2 " +
                     "AND end_time IS NOT NULL " +
                     "AND start_time IS NOT NULL " +
                     "AND end_time > start_time";

        try {
            Query query = entityManager.createNativeQuery(sql);
            Object result = query.getSingleResult();

            if (result instanceof BigDecimal bigDecimal) {
                return bigDecimal.doubleValue();
            }
            return 0.0;
        } catch (Exception e) {
            return 0.0;
        }
    }

    /**
     * Gestion des erreurs avec valeurs par d√©faut
     */
    private void handleStatsError(ProcessStatsDTO stats, Exception e) {
        logger.error("Erreur lors du calcul des statistiques de base: {}", e.getMessage());

        // Valeurs par d√©faut en cas d'erreur
        stats.setTotalInstances(0L);
        stats.setActiveInstances(0L);
        stats.setCompletedInstances(0L);
        stats.setAbortedInstances(0L);
        stats.setSuspendedInstances(0L);
        stats.setErrorInstances(0L);
        stats.setInstancesLast24Hours(0L);
        stats.setInstancesLast7Days(0L);
        stats.setInstancesByProcess(new HashMap<>());
        stats.setAverageDurationMs(0.0);
    }
}
